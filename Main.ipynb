{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Main.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard","widgets":{"application/vnd.jupyter.widget-state+json":{"e14ef9e9779e425eaefd3c3145a3b3d2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b1710e2b7d61405186a6aa14e46c2f73","IPY_MODEL_f02933b938a6440e990bdaed8ed139e1","IPY_MODEL_26f584d30a2e44c19db15642176b9446"],"layout":"IPY_MODEL_a3a37720ebeb46f89100585f31bff0a1"}},"b1710e2b7d61405186a6aa14e46c2f73":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6889d8a662444b779e40cfa2c7f22cf2","placeholder":"​","style":"IPY_MODEL_df8f791a02cd46df887db2c7703fbae5","value":"Downloading: 100%"}},"f02933b938a6440e990bdaed8ed139e1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f18b1811c8934dc89f6d580a181491df","max":687,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3da52e556a754c698461e121ff34c7db","value":687}},"26f584d30a2e44c19db15642176b9446":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2504bce3ce84446ca104e83b034c84bf","placeholder":"​","style":"IPY_MODEL_557f96a6801e4faeb37f300a9b0978ce","value":" 687/687 [00:00&lt;00:00, 18.7kB/s]"}},"a3a37720ebeb46f89100585f31bff0a1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6889d8a662444b779e40cfa2c7f22cf2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"df8f791a02cd46df887db2c7703fbae5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f18b1811c8934dc89f6d580a181491df":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3da52e556a754c698461e121ff34c7db":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2504bce3ce84446ca104e83b034c84bf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"557f96a6801e4faeb37f300a9b0978ce":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"view-in-github"},"source":["<a href=\"https://colab.research.google.com/github/ayami-n/Flax_text_prediction/blob/main/Main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"2DeZbEYMnwWN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%cd /content/drive/MyDrive/Flax_text_prediction"],"metadata":{"id":"qhezgqRvnzTS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1658039247117,"user_tz":-600,"elapsed":646,"user":{"displayName":"Yuji Ishikawa","userId":"17475269684774678602"}},"outputId":"642b530c-9c8e-4f0b-8e1c-63f0060934d9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Flax_text_prediction\n"]}]},{"cell_type":"markdown","source":["# Import libs"],"metadata":{"id":"NRKyEoECnnSd"}},{"cell_type":"code","source":["%%capture\n","!pip install datasets\n","!pip install git+https://github.com/huggingface/transformers.git\n","!pip install flax\n","!pip install git+https://github.com/deepmind/optax.git"],"metadata":{"id":"Iv2TRPsJpyAM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import jax\n","from jax import random  # to create random values for initalizing a model (Flax requires)\n","import jax.numpy as jnp\n","\n","# Flax for building model\n","try:\n","    import flax\n","except ModuleNotFoundError: # Install flax if missing\n","    !pip install --quiet flax\n","    import flax\n","\n","from flax import linen as nn\n","from flax.training import train_state, checkpoints\n","\n","# Optax for optimizor \n","import optax\n","\n","# Transformers\n","!pip install transformers\n","from transformers import FlaxAutoModelForSequenceClassification, AutoConfig\n","from transformers import RobertaTokenizer, RobertaConfig # as we use Roberta model\n","\n","# others\n","import pandas as pd\n","from tqdm import tqdm"],"metadata":{"id":"epCnK0nRnmhW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1658040123238,"user_tz":-600,"elapsed":3195,"user":{"displayName":"Yuji Ishikawa","userId":"17475269684774678602"}},"outputId":"b2bced1c-d8c3-4b1f-8b65-69137bfb8330"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.20.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.8.1)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n"]}]},{"cell_type":"markdown","source":["# Config"],"metadata":{"id":"IVImuz8mpJXl"}},{"cell_type":"code","source":["model_checkpoint = 'siebert/sentiment-roberta-large-english' # https://huggingface.co/docs/transformers/model_doc/roberta#roberta\n","num_labels = 3 # our targets\n","seed = 0  # for building our model\n","max_len = 256  # input text should be the same length\n","\n","config = AutoConfig.from_pretrained(model_checkpoint, num_labels=num_labels)  # create a config for our model\n","tokenizer = RobertaTokenizer.from_pretrained(model_checkpoint)  # this tokenizer converts numeric from string: the values are different if you select different model_checkpoint"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["e14ef9e9779e425eaefd3c3145a3b3d2","b1710e2b7d61405186a6aa14e46c2f73","f02933b938a6440e990bdaed8ed139e1","26f584d30a2e44c19db15642176b9446","a3a37720ebeb46f89100585f31bff0a1","6889d8a662444b779e40cfa2c7f22cf2","df8f791a02cd46df887db2c7703fbae5","f18b1811c8934dc89f6d580a181491df","3da52e556a754c698461e121ff34c7db","2504bce3ce84446ca104e83b034c84bf","557f96a6801e4faeb37f300a9b0978ce"]},"id":"roAJE2JZpLjv","executionInfo":{"status":"ok","timestamp":1658039279342,"user_tz":-600,"elapsed":2454,"user":{"displayName":"Yuji Ishikawa","userId":"17475269684774678602"}},"outputId":"536f2dc5-ac37-4360-9922-0369de27ffb4"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/687 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e14ef9e9779e425eaefd3c3145a3b3d2"}},"metadata":{}}]},{"cell_type":"markdown","source":["# Tokenaization"],"metadata":{"id":"zduhy-t_m7q1"}},{"cell_type":"code","source":["df = pd.read_csv(\"./kaggle/train.csv\")  # import train datasets\n","new_label = {\"discourse_effectiveness\": {\"Ineffective\": 0, \"Adequate\": 1, \"Effective\": 2}}  # to replace \n","df = df.replace(new_label) "],"metadata":{"id":"MBotyWi7nFlv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def tokenaize(texts, tokenizer, max_len):  # df text comes and return as numerical \n","    input_ids = []\n","    attention_mask = []\n","    \n","    for text in tqdm(texts):  # it takes over 1 min (numpy and list)\n","        token = tokenizer(text, max_length=max_len, truncation=True, padding='max_length',\n","                         add_special_tokens=True,  return_tensors='jax')\n","        input_ids.append(token['input_ids']) # separate: the values (text) are converted by the tokenizer\n","        attention_mask.append(token['attention_mask']) # separate: the values (attention-mask) are converted by the tokenizer\n","        \n","    return jnp.array(input_ids), jnp.array(attention_mask)"],"metadata":{"id":"DobpcytJn15n"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["input_ids, attention_mask = tokenaize(df['discourse_text'].to_numpy(), tokenizer, max_len)  # pandas is slow -> numpy is the fastest (list is considerable)\n","\n","print(input_ids)\n","print(attention_mask)"],"metadata":{"id":"FqZ_TapDqXwR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Create a model"],"metadata":{"id":"2FC74pNhnDIW"}},{"cell_type":"code","source":["model = FlaxAutoModelForSequenceClassification.from_pretrained(model_checkpoint, config=config, seed=seed, ignore_mismatched_sizes=True)  # ignore_mismatched_sizes=True: arrow to have arbitary number of outputs"],"metadata":{"id":"Z0V58UuSs4EW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1657868739612,"user_tz":-600,"elapsed":3356,"user":{"displayName":"Yuji Ishikawa","userId":"17475269684774678602"}},"outputId":"765f61a9-885b-419f-b58c-287d67b9e921"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of FlaxRobertaForSequenceClassification were not initialized from the model checkpoint at siebert/sentiment-roberta-large-english and are newly initialized because the shapes did not match:\n","- ('classifier', 'out_proj', 'bias'): found shape (2,) in the checkpoint and (3,) in the model instantiated\n","- ('classifier', 'out_proj', 'kernel'): found shape (1024, 2) in the checkpoint and (1024, 3) in the model instantiated\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}]},{"cell_type":"code","source":["out = model(**inputs)\n","print(out)\n","print(out.logits)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hjtVxyp1uCtN","executionInfo":{"status":"ok","timestamp":1657868770007,"user_tz":-600,"elapsed":5676,"user":{"displayName":"Yuji Ishikawa","userId":"17475269684774678602"}},"outputId":"62f5cb1b-02a5-4efe-a29d-79544beb1657"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["FlaxSequenceClassifierOutput(logits=DeviceArray([[-0.4148041 , -0.48419115,  0.02517768]], dtype=float32), hidden_states=None, attentions=None)\n","[[-0.4148041  -0.48419115  0.02517768]]\n"]}]},{"cell_type":"markdown","source":["# Validation"],"metadata":{"id":"CpxQhQs3RerZ"}},{"cell_type":"code","source":["test = pd.read_csv(\"./kaggle/test.csv\") "],"metadata":{"id":"8omD1G1mRhXa"},"execution_count":null,"outputs":[]}]}