{"cells":[{"cell_type":"markdown","metadata":{"id":"view-in-github"},"source":["<a href=\"https://colab.research.google.com/github/ayami-n/Flax_text_prediction/blob/main/Main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":77920,"status":"ok","timestamp":1658831909825,"user":{"displayName":"Yuji Ishikawa","userId":"17475269684774678602"},"user_tz":-600},"id":"2DeZbEYMnwWN","outputId":"409ccf0b-b186-4fab-acfa-cc98178af40b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1658831983208,"user":{"displayName":"Yuji Ishikawa","userId":"17475269684774678602"},"user_tz":-600},"id":"qhezgqRvnzTS","outputId":"58ade6fb-f36e-491c-89dc-396231db049d"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/MyDrive/Flax_text_prediction\n"]}],"source":["%cd /content/drive/MyDrive/Flax_text_prediction"]},{"cell_type":"markdown","metadata":{"id":"NRKyEoECnnSd"},"source":["# Import libs"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Iv2TRPsJpyAM"},"outputs":[],"source":["%%capture\n","!pip install git+https://github.com/huggingface/transformers.git\n","!pip install flax\n","!pip install git+https://github.com/deepmind/optax.git"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19197,"status":"ok","timestamp":1658832052895,"user":{"displayName":"Yuji Ishikawa","userId":"17475269684774678602"},"user_tz":-600},"id":"epCnK0nRnmhW","outputId":"04dd706b-5e6a-410f-c17c-f256cd6ad69d"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[K     |████████████████████████████████| 202 kB 25.1 MB/s \n","\u001b[K     |████████████████████████████████| 217 kB 68.1 MB/s \n","\u001b[K     |████████████████████████████████| 145 kB 74.2 MB/s \n","\u001b[K     |████████████████████████████████| 596 kB 63.3 MB/s \n","\u001b[K     |████████████████████████████████| 9.1 MB 63.9 MB/s \n","\u001b[K     |████████████████████████████████| 51 kB 6.4 MB/s \n","\u001b[K     |████████████████████████████████| 72 kB 709 kB/s \n","\u001b[?25hLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.20.1-py3-none-any.whl (4.4 MB)\n","\u001b[K     |████████████████████████████████| 4.4 MB 24.6 MB/s \n","\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n","  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n","\u001b[K     |████████████████████████████████| 6.6 MB 54.4 MB/s \n","\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n","Collecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.8.1-py3-none-any.whl (101 kB)\n","\u001b[K     |████████████████████████████████| 101 kB 15.4 MB/s \n","\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.1)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.8.1 tokenizers-0.12.1 transformers-4.20.1\n"]}],"source":["import jax\n","from jax import random  # to create random values for initalizing a model (Flax requires)\n","import jax.numpy as jnp\n","\n","# Flax for building model\n","try:\n","    import flax\n","except ModuleNotFoundError: # Install flax if missing\n","    !pip install --quiet flax\n","    import flax\n","    \n","from flax import linen as nn\n","from flax.training import train_state, checkpoints\n","from flax.core.frozen_dict import freeze, unfreeze\n","from flax import traverse_util\n","\n","# Optax for optimizor \n","import optax\n","\n","# Transformers\n","!pip install transformers\n","from transformers import FlaxAutoModelForSequenceClassification, RobertaTokenizer, RobertaConfig # as we use Roberta model\n","from transformers.modeling_flax_utils import FlaxPreTrainedModel  # FlaxMLPModule is still stateless\n","\n","# others\n","import pandas as pd\n","from tqdm import tqdm\n","from typing import Callable, Any\n","from sklearn.model_selection import train_test_split\n","from torch.utils.data import DataLoader, Dataset\n","import numpy as np\n","!pip install datasets\n","from datasets import load_dataset"]},{"cell_type":"markdown","metadata":{"id":"IVImuz8mpJXl"},"source":["# Config for Model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":177,"referenced_widgets":["032575f656694ef38872152df3cf674c","ee1fbade1c974baba43685aecc76b818","c3a1a7d35a06417e88e34e822021e561","a4909d70e0ba42a2a6da8f9b3cec88ce","34b0db12710240b5bcff175ffa4c96f4"]},"executionInfo":{"elapsed":1275,"status":"ok","timestamp":1658832057867,"user":{"displayName":"Yuji Ishikawa","userId":"17475269684774678602"},"user_tz":-600},"id":"roAJE2JZpLjv","outputId":"6555549a-d8f8-4d08-ed1b-279caad94168"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"032575f656694ef38872152df3cf674c","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/780k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ee1fbade1c974baba43685aecc76b818","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/446k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c3a1a7d35a06417e88e34e822021e561","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/150 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a4909d70e0ba42a2a6da8f9b3cec88ce","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/256 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"34b0db12710240b5bcff175ffa4c96f4","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/687 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["model_checkpoint = 'siebert/sentiment-roberta-large-english' # https://huggingface.co/docs/transformers/model_doc/roberta#roberta\n","seed = 0  # for building our model\n","\n","tokenizer = RobertaTokenizer.from_pretrained(model_checkpoint)  # this tokenizer converts numeric from string: the values are different if you select different model_checkpoint"]},{"cell_type":"markdown","metadata":{"id":"zduhy-t_m7q1"},"source":["# Tokenaization and Loading Data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YDDiF-Nkv-qH"},"outputs":[],"source":["'''\n","https://stackoverflow.com/questions/65246703/how-does-max-length-padding-and-truncation-arguments-work-in-huggingface-bertt\n","adding [CLS] token at the beginning of the sentence, and [SEP] token at the end of sentence.\n","[CLS] I love you [SEP] is expected by BERT. \n","tokenizer gives [CLS] and [SEP] usually\n","'''"]},{"cell_type":"markdown","source":["## Data Analysis"],"metadata":{"id":"jPrY66m2qQqv"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":324,"status":"ok","timestamp":1658638712668,"user":{"displayName":"Yuji Ishikawa","userId":"17475269684774678602"},"user_tz":-600},"id":"a1Xx753jpyup","outputId":"11abc712-ad62-443e-d366-c2a1b24c549f"},"outputs":[{"name":"stdout","output_type":"stream","text":["36566 36765\n"]}],"source":["df = pd.read_csv(\"./kaggle/train.csv\")  # import train datasets\n","max = 0\n","max_str = \"Who is Max?\"\n","words_list = []\n","for itr, val in enumerate(df['discourse_text'].to_numpy()):\n","  words = val.split()\n","  words_list.append(len(words))\n","\n","  if len(words) > max:\n","    max = len(words)\n","    max_str = val\n","\n","print(pd.Series(list(filter(lambda x: (x <= 256), words_list))).count(), len(words_list))    "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":283},"executionInfo":{"elapsed":724,"status":"ok","timestamp":1658212132122,"user":{"displayName":"Ayami Nonaka","userId":"17110434711451596966"},"user_tz":-600},"id":"qYQS1fZEI0Ip","outputId":"9a8ac7a9-aebd-4d25-8ed6-e4a08ceb4c5f"},"outputs":[{"data":{"text/plain":["<matplotlib.axes._subplots.AxesSubplot at 0x7ff1f7bf1410>"]},"execution_count":36,"metadata":{},"output_type":"execute_result"},{"data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["'''\n","https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.plot.kde.html\n","'''\n","pd.Series(words_list).plot.kde()  # most words are less than 250"]},{"cell_type":"markdown","source":["## Creating Dummy Inputs"],"metadata":{"id":"kHCVYVNVqVcP"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"DobpcytJn15n"},"outputs":[],"source":["train_df, val_df = train_test_split(df, test_size=0.05, random_state=seed)  # spliting datasets 95% train and 5% val\n","\n","max_len = 256  # input text should be the same length (most words <= 256)\n","\n","dummy = tokenizer(train_df['discourse_text'].to_numpy()[:1][0], # [:1][0] -> makes str\n","                  max_length=max_len, truncation=True, \n","                  padding='max_length', \n","                  return_tensors='jax') # add_special_tokens=True is default: truncation=True is cutting off longer sentences (longer than max_length)\n","\n","dummy_input_ids, dummy_attention_mask = dummy['input_ids'], dummy['attention_mask']  # jax: the values (text) are converted by the tokenizer, the values (attention-mask) are converted by the tokenizer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fWpACWVPZt28"},"outputs":[],"source":["tokenizer.convert_ids_to_tokens(dummy_input_ids.squeeze())[:30]  # checking the converted id's"]},{"cell_type":"markdown","metadata":{"id":"ihzhOQDtACZ3"},"source":["## Loading Data"]},{"cell_type":"code","source":["data = load_dataset(\"csv\", data_files={'train': \"./kaggle/train.csv\"]})\n","data = data[\"train\"].train_test_split(0.05)"],"metadata":{"id":"n3T6921Ln-2v"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def preprocess_function(input_batch):\n","   \n","    texts = (input_batch[\"discourse_text\"],)\n","    processed = tokenizer(*texts, \n","                          max_length=256, \n","                          truncation=True, padding='max_length', \n","                          return_tensors='np')     \n","    \n","    # replace label -> numerical\n","    processed[\"labels\"] = input_batch[\"discourse_effectiveness\"]\n","    new_label = {\"Ineffective\": 0, \"Adequate\": 1, \"Effective\": 2}\n","    processed[\"labels\"] = [x if x not in new_label else new_label[x] for x in processed[\"labels\"]]\n","    \n","    return processed"],"metadata":{"id":"DiXsG3NgoU4l"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tokenized_dataset = data.map(preprocess_function, batched=True, remove_columns=data[\"train\"].column_names)\n","train_dataset = tokenized_dataset[\"train\"]\n","validation_dataset = tokenized_dataset[\"test\"]"],"metadata":{"id":"laM2kQrwpc4c"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2FC74pNhnDIW"},"source":["# Create a model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["e78176adf4e6446c8d920328e3034e13"]},"executionInfo":{"elapsed":52325,"status":"ok","timestamp":1658820834961,"user":{"displayName":"Yuji Ishikawa","userId":"17475269684774678602"},"user_tz":-600},"id":"Z0V58UuSs4EW","outputId":"65622681-ad16-4a99-fbad-bb61bc08c6c5"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e78176adf4e6446c8d920328e3034e13","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/1.32G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["# the model size is 1.32G\n","pretrained_roberta = FlaxAutoModelForSequenceClassification.from_pretrained(model_checkpoint, seed=seed)  "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xKelFbLy22Am"},"outputs":[],"source":["class MyNLP(nn.Module):\n","    roberta: nn.Module\n","\n","    @nn.compact\n","    def __call__(self, input_ids, attention_mask, train=True):  # https://jalammar.github.io/a-visual-guide-to-using-bert-for-the-first-time/ \n","        out = self.roberta(input_ids, attention_mask, output_hidden_states=True)  # extract all hidden layers: but we need the last (attention) layer, in particular, [CLS]  \n","        cls_embedding = out.hidden_states[0][:,0,:] # (1, 1024): [:,0,:] -> first : is all sentences, 0 is [CLS], last : is all hidden unit outputs\n","\n","        #### Transfer Learning: name should be alpabet orders for the summary ####\n","        out = nn.Dense(features=512, name=\"A\")(input_ids)  \n","        out = nn.Dense(features=256, name=\"B\")(out)\n","\n","        out = nn.Dropout(0.1, deterministic=True, name='C')(out)  # deteministic=true: no mask and apply the rate\n","\n","        out = nn.Dense(features=64, name=\"D\")(out)\n","        out = nn.Dense(features=3, name=\"E\")(out)\n","        # out = nn.softmax(out)\n","\n","        return out"]},{"cell_type":"markdown","metadata":{"id":"y0PqeEUODU7c"},"source":["# Define Loss"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZAaS0H-iDXJT"},"outputs":[],"source":["def cross_entropy_loss(logits, labels, num_classes):\n","  labels_onehot = jax.nn.one_hot(labels, num_classes=num_classes)\n","  return optax.softmax_cross_entropy(logits=logits, labels=labels_onehot).mean()   # return example: 0.96834594"]},{"cell_type":"markdown","metadata":{"id":"RHOpaszTDrWs"},"source":["# Compute Metrics"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AL8_UoDqDu68"},"outputs":[],"source":["def compute_metrics(*, logits, labels):\n","  num_classes = len(logits[-1])\n","  loss = cross_entropy_loss(logits, labels, num_classes)\n","  accuracy = jnp.mean(jnp.argmax(logits, -1) == labels)\n","\n","  metrics = {\n","      'loss': loss,\n","      'accuracy': accuracy,\n","  }\n","  return metrics"]},{"cell_type":"markdown","metadata":{"id":"nSXdLv2_Lsec"},"source":["## Define the Training State"]},{"cell_type":"code","source":["### Train Config ####\n","\n","num_train_epochs = 5\n","learning_rate = 2e-5\n","per_device_batch_size = 32\n","weight_decay=1e-2\n","\n","total_batch_size = per_device_batch_size * jax.local_device_count()\n","num_train_steps = len(train_dataset) // total_batch_size * num_train_epochs\n","learning_rate_function = optax.cosine_onecycle_schedule(transition_steps=num_train_steps, peak_value=learning_rate, pct_start=0.1)"],"metadata":{"id":"bNqymunxq3EV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class TrainState(train_state.TrainState):\n","    '''\n","    Derived TrainState class that saves the forward pass of the model as an eval function and a loss function\n","    '''\n","    logits_function: Callable = flax.struct.field(pytree_node=False)\n","    loss_function: Callable = flax.struct.field(pytree_node=False)"],"metadata":{"id":"cgiSdpmKrPQs"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_8CTCLFLCzRU"},"outputs":[],"source":["def create_train_state(seed, pretrained_model, dummy_input_ids, dummy_attention_mask, lr):  \n","\n","  ### initialize the model ###\n","  init_rng = jax.random.PRNGKey(seed)\n","\n","  model = MyNLP(pretrained_model)  # create a model\n","  print(model.tabulate(init_rng, dummy_input_ids, dummy_attention_mask))  # display the summary\n","  variables = model.init(init_rng, dummy_input_ids, dummy_attention_mask)  # store [A-E] variables\n","\n","  # inserting the pretrained parameters into the correct place on the new parameter structure as names will matter \n","  #### add randomly initialized params with pretrained params ####\n","  variables = unfreeze(variables)  # unfreeze: Makes a mutable copy of a FrozenDict mutable by transforming it into (nested) dict\n","  variables['params']['RoberTa'] = pretrained_roberta.params  # adding roberta params to the randomly initialized params\n","  variables = freeze(variables)  # freeze: An immutable variant of the Python dict.\n","  \n","  #### Falx updates parmas while the training phase ####\n","  def decay_mask_fn(params):\n","    '''\n","    This function's task is to make sure that weight decay is not applies to any bias or Layernorm weights\n","    '''\n","    flat_params = traverse_util.flatten_dict(params)\n","    flat_mask = {path: (path[-1] != \"bias\" and path[-2:] != (\"LayerNorm\", \"scale\")) for path in flat_params}\n","    return traverse_util.unflatten_dict(flat_mask)\n","\n","  # Adam optimizer function using optax.adamw\n","  def adamw(weight_decay):\n","    return optax.adamw(learning_rate=learning_rate_function, b1=0.9, b2=0.999, eps=1e-6, weight_decay=weight_decay,mask=decay_mask_fn)\n","  \n","  opt = adamw(weight_decay)\n","\n","  state = train_state.TrainState.create(\n","      apply_fn=model.apply,\n","      params=variables['params'],\n","      tx=opt, \n","      loss_function=cross_entropy_loss\n","      )\n","  \n","  return state"]},{"cell_type":"markdown","metadata":{"id":"6tAvtp892XB7"},"source":["# Define the Training/Evaluation Steps"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"J2oOIhK_FYcU"},"outputs":[],"source":["def compute_loss(state, params, input_ids, attention_mask, labels):\n","    logits = state.apply_fn({'params': params}, input_ids, attention_mask)  # example return: DeviceArray([[0.15097128, 0.6676195 , 0.18140921]], dtype=float32)\n","    loss = cross_entropy_loss(logits=logits, labels=labels, num_classes=len(logits[-1]))  # example return 0.40403685\n","    return loss, logits"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Pye8tZXJGcQC"},"outputs":[],"source":["@jax.jit\n","def train_step(state, input_ids, attention_mask, labels):  # softmax\n","\n","  # do the forward pass and get the loss and gradients\n","  grad_function = jax.value_and_grad(compute_loss, has_aux=True, allow_int=True)  # def loss_function(params) is wrapped by Jax to calculate loss and gradient\n","  (loss, logits), grad = grad_function(state, state.params, input_ids, attention_mask, labels)\n","\n","  # this function calls tx.update() followed by a call to optax.apply_updates() to update params and opt_state\n","  new_state = state.apply_gradients(grads=grad)  # update params with Adam  \n","  # metrics = compute_metrics(logits=logits, labels=labels) \n","  \n","  return new_state #, metrics"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KqeDnJwjIKC0"},"outputs":[],"source":["@jax.jit\n","def eval_step(state, input_ids, attention_mask, labels):  # argmax\n","    logits = state.apply_fn({'params': state.params}, input_ids, attention_mask, labels)\n","    return compute_metrics(logits=logits, labels=labels)  # return loss and accuracy"]},{"cell_type":"markdown","metadata":{"id":"k4SBvNboIwx8"},"source":["# Main Functions"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5BbgbXO2K6vU"},"outputs":[],"source":["def train_one_epoch(state, dataloader):\n","    \"\"\"Train for 1 epoch on the training set.\"\"\"\n","    batch_metrics = []\n","    for itr, (train_input_ids, train_attention_mask, train_label) in enumerate(train):        \n","        state, metrics = train_step(state, train_input_ids, train_attention_mask, train_label)\n","        batch_metrics.append(metrics)\n","\n","    batch_metrics_np = jax.device_get(batch_metrics)  \n","    epoch_metrics_np = {\n","        k: np.mean([metrics[k] for metrics in batch_metrics_np])\n","        for k in batch_metrics_np[0]\n","    }\n","\n","    return state, epoch_metrics_np"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dKyzsfNKp4Tj"},"outputs":[],"source":["state = create_train_state(seed, pretrained_roberta, dummy_input_ids, dummy_attention_mask, 2e-5)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5IJ1hwPfqs5C"},"outputs":[],"source":["state.params"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6362,"status":"ok","timestamp":1658824888003,"user":{"displayName":"Yuji Ishikawa","userId":"17475269684774678602"},"user_tz":-600},"id":"Xg_vMBZWnnwM","outputId":"327a6e7f-d045-4744-8528-94a6b3f0827f"},"outputs":[{"data":{"text/plain":["DeviceArray([[5726.1973, 3089.8079, 6497.5693]], dtype=float32)"]},"execution_count":96,"metadata":{},"output_type":"execute_result"}],"source":["logits = state.apply_fn({'params': state.params}, dummy_input_ids, dummy_attention_mask)\n","logits"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"R5NK4DlCi2GT"},"outputs":[],"source":["batch_metrics = []\n","for itr, (train_input_ids, train_attention_mask, train_label) in enumerate(val):        \n","    state, metrics = train_step(state, train_input_ids, train_attention_mask, train_label)\n","    batch_metrics.append(metrics)\n","\n","    batch_metrics_np = jax.device_get(batch_metrics)  \n","    epoch_metrics_np = {\n","        k: np.mean([metrics[k] for metrics in batch_metrics_np])\n","        for k in batch_metrics_np[0]\n","    }\n","\n","    if itr == 2: \n","      break"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HBnv_FfLUukK"},"outputs":[],"source":["def evaluate_model(state, val):\n","    \"\"\"Evaluate on the validation set.\"\"\"\n","    for itr, (val_input_ids, val_attention_mask, val_label) in enumerate(val):   \n","      metrics = eval_step(state, val_input_ids, val_attention_mask, val_label)\n","      metrics = jax.device_get(metrics) \n","      metrics = jax.tree_map(lambda x: x.item(), metrics)  \n","    return metrics"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ej1t_WsHVNEM"},"outputs":[],"source":["def main(seed, pretrained_roberta, dummy_input_ids, dummy_attention_mask):\n","  num_epochs = 2\n","  \n","  training_loss = []\n","  training_accuracy = []\n","  testing_loss = []\n","  testing_accuracy = []\n","\n","  state = create_train_state(seed, pretrained_roberta, dummy_input_ids, dummy_attention_mask, 2e-5)\n","\n","  for epoch in range(num_epochs):\n","      new_state, new_metrics = train_one_epoch(state, train)\n","      training_loss.append(new_metrics['loss'])\n","      training_accuracy.append(new_metrics['accuracy'])\n","      print(f\"Train epoch: {epoch}, loss: {new_metrics['loss']}, accuracy: {new_metrics['accuracy'] * 100}\")\n","\n","      # if epoch % 2 == 0:\n","      #   test_metrics = evaluate_model(train_state, val)\n","      #   testing_loss.append(test_metrics['loss'])\n","      #   testing_accuracy.append(test_metrics['accuracy'])\n","      #   print(f\"Test epoch: {epoch}, loss: {test_metrics['loss']}, accuracy: {test_metrics['accuracy'] * 100}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":484},"executionInfo":{"elapsed":740,"status":"error","timestamp":1658824017908,"user":{"displayName":"Yuji Ishikawa","userId":"17475269684774678602"},"user_tz":-600},"id":"J5oHF1RVWocs","outputId":"5906a524-80c3-46dc-b7db-79fa686ed324"},"outputs":[{"ename":"TypeError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mUnfilteredStackTrace\u001b[0m                      Traceback (most recent call last)","\u001b[0;32m<ipython-input-55-8100dee7996a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpretrained_roberta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdummy_input_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdummy_attention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-54-b1fe6c95563f>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(seed, pretrained_roberta, dummy_input_ids, dummy_attention_mask)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m   \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_train_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpretrained_roberta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdummy_input_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdummy_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2e-5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-26-c65f1ca8f11c>\u001b[0m in \u001b[0;36mcreate_train_state\u001b[0;34m(seed, pretrained_model, dummy_input_ids, dummy_attention_mask, lr)\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMyNLP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# create a model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtabulate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit_rng\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdummy_input_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdummy_attention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# display the summary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m   \u001b[0mvariables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit_rng\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdummy_input_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdummy_attention_mask\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# store [A-E] variables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/flax/linen/summary.py\u001b[0m in \u001b[0;36m_tabulate_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    172\u001b[0m                                  exclude_methods=set(exclude_methods))\n\u001b[0;32m--> 173\u001b[0;31m     \u001b[0mtable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_render_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/flax/linen/summary.py\u001b[0m in \u001b[0;36m_get_table_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m     shape_variables = jax.eval_shape(lambda: module.init(\n\u001b[0m\u001b[1;32m    201\u001b[0m         \u001b[0mrngs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/flax/linen/summary.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    205\u001b[0m         \u001b[0mcapture_intermediates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcapture_intermediates\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m         \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     ))\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/_src/traceback_util.py\u001b[0m in \u001b[0;36mreraise_with_filtered_traceback\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/flax/linen/module.py\u001b[0m in \u001b[0;36minit\u001b[0;34m(self, rngs, method, mutable, capture_intermediates, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1271\u001b[0m         \u001b[0mcapture_intermediates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcapture_intermediates\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1272\u001b[0;31m         **kwargs)\n\u001b[0m\u001b[1;32m   1273\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mv_out\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/_src/traceback_util.py\u001b[0m in \u001b[0;36mreraise_with_filtered_traceback\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/flax/linen/module.py\u001b[0m in \u001b[0;36minit_with_output\u001b[0;34m(self, rngs, method, mutable, capture_intermediates, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1226\u001b[0m         \u001b[0mcapture_intermediates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcapture_intermediates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1227\u001b[0;31m     )(rngs, *args, **kwargs)\n\u001b[0m\u001b[1;32m   1228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/flax/core/scope.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(rngs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    896\u001b[0m     return apply(fn, mutable=mutable, flags=init_flags)({}, *args, rngs=rngs,\n\u001b[0;32m--> 897\u001b[0;31m                                                         **kwargs)\n\u001b[0m\u001b[1;32m    898\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/flax/core/scope.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(variables, rngs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    863\u001b[0m               flags=flags).temporary() as root:\n\u001b[0;32m--> 864\u001b[0;31m       \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    865\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmutable\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/flax/linen/module.py\u001b[0m in \u001b[0;36mscope_fn\u001b[0;34m(scope, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1639\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1640\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1641\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/flax/linen/transforms.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0mfull_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'{module_name}{method_suffix}'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1320\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfull_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1321\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.7/contextlib.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recreate_cm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/flax/linen/module.py\u001b[0m in \u001b[0;36mwrapped_module_method\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    352\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_wrapped_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/flax/linen/module.py\u001b[0m in \u001b[0;36m_call_wrapped_method\u001b[0;34m(self, fun, args, kwargs)\u001b[0m\n\u001b[1;32m    651\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 652\u001b[0;31m       \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    653\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0m_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcapture_stack\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-52-ea1878005f21>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, input_ids, attention_mask, train)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;31m#### Transfer Learning: name should be alpabet orders for the summary ####\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"A\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"B\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/flax/linen/transforms.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0mfull_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'{module_name}{method_suffix}'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1320\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfull_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1321\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.7/contextlib.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recreate_cm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/flax/linen/module.py\u001b[0m in \u001b[0;36mwrapped_module_method\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    352\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_wrapped_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/flax/linen/module.py\u001b[0m in \u001b[0;36m_call_wrapped_method\u001b[0;34m(self, fun, args, kwargs)\u001b[0m\n\u001b[1;32m    651\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 652\u001b[0;31m       \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    653\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0m_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcapture_stack\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mUnfilteredStackTrace\u001b[0m: TypeError: __call__() takes 2 positional arguments but 3 were given\n\nThe stack trace below excludes JAX-internal frames.\nThe preceding is the original exception that occurred, unmodified.\n\n--------------------","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-55-8100dee7996a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpretrained_roberta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdummy_input_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdummy_attention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-54-b1fe6c95563f>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(seed, pretrained_roberta, dummy_input_ids, dummy_attention_mask)\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0mtesting_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m   \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_train_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpretrained_roberta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdummy_input_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdummy_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2e-5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-26-c65f1ca8f11c>\u001b[0m in \u001b[0;36mcreate_train_state\u001b[0;34m(seed, pretrained_model, dummy_input_ids, dummy_attention_mask, lr)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMyNLP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# create a model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtabulate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit_rng\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdummy_input_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdummy_attention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# display the summary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m   \u001b[0mvariables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit_rng\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdummy_input_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdummy_attention_mask\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# store [A-E] variables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/flax/linen/module.py\u001b[0m in \u001b[0;36mtabulate\u001b[0;34m(self, rngs, method, mutable, depth, exclude_methods, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1490\u001b[0m                                    \u001b[0mmutable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmutable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdepth\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1491\u001b[0m                                    exclude_methods=exclude_methods)\n\u001b[0;32m-> 1492\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtabulate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1494\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/flax/linen/summary.py\u001b[0m in \u001b[0;36m_tabulate_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    171\u001b[0m                                  \u001b[0mmutable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmutable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdepth\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m                                  exclude_methods=set(exclude_methods))\n\u001b[0;32m--> 173\u001b[0;31m     \u001b[0mtable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_render_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/flax/linen/summary.py\u001b[0m in \u001b[0;36m_get_table_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m     shape_variables = jax.eval_shape(lambda: module.init(\n\u001b[0m\u001b[1;32m    201\u001b[0m         \u001b[0mrngs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/_src/api.py\u001b[0m in \u001b[0;36meval_shape\u001b[0;34m(fun, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3085\u001b[0m   out = pe.abstract_eval_fun(wrapped_fun.call_wrapped,\n\u001b[1;32m   3086\u001b[0m                              \u001b[0;34m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshaped_abstractify\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs_flat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3087\u001b[0;31m                              debug_info=debug_info)\n\u001b[0m\u001b[1;32m   3088\u001b[0m   \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mShapeDtypeStruct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_shape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3089\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mtree_unflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/interpreters/partial_eval.py\u001b[0m in \u001b[0;36mabstract_eval_fun\u001b[0;34m(fun, debug_info, *avals, **params)\u001b[0m\n\u001b[1;32m    528\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mabstract_eval_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mavals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdebug_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m   _, avals_out, _ = trace_to_jaxpr_dynamic(\n\u001b[0;32m--> 530\u001b[0;31m       lu.wrap_init(fun, params), avals, debug_info)\n\u001b[0m\u001b[1;32m    531\u001b[0m   \u001b[0;32massert\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAbstractValue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0maval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mavals_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mavals_out\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/_src/profiler.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    310\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mTraceAnnotation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mdecorator_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/interpreters/partial_eval.py\u001b[0m in \u001b[0;36mtrace_to_jaxpr_dynamic\u001b[0;34m(fun, in_avals, debug_info, keep_inputs)\u001b[0m\n\u001b[1;32m   1876\u001b[0m     \u001b[0mmain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjaxpr_stack\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1877\u001b[0m     jaxpr, out_avals, consts = trace_to_subjaxpr_dynamic(\n\u001b[0;32m-> 1878\u001b[0;31m       fun, main, in_avals, keep_inputs=keep_inputs)\n\u001b[0m\u001b[1;32m   1879\u001b[0m     \u001b[0;32mdel\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1880\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mjaxpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_avals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/interpreters/partial_eval.py\u001b[0m in \u001b[0;36mtrace_to_subjaxpr_dynamic\u001b[0;34m(fun, main, in_avals, keep_inputs)\u001b[0m\n\u001b[1;32m   1890\u001b[0m     \u001b[0min_tracers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_input_type_to_tracers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_avals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1891\u001b[0m     \u001b[0min_tracers_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_tracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_inputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mkeep\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1892\u001b[0;31m     \u001b[0mans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_wrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0min_tracers_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1893\u001b[0m     \u001b[0mout_tracers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_raise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1894\u001b[0m     \u001b[0mjaxpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_jaxpr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_tracers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/linear_util.py\u001b[0m in \u001b[0;36mcall_wrapped\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m       \u001b[0mans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m     \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m       \u001b[0;31m# Some transformations yield from inside context managers, so we have to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/linear_util.py\u001b[0m in \u001b[0;36mcall_wrapped\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m       \u001b[0mans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m     \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m       \u001b[0;31m# Some transformations yield from inside context managers, so we have to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/flax/linen/summary.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0mmutable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmutable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m         \u001b[0mcapture_intermediates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcapture_intermediates\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m         \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     ))\n\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.7/contextlib.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recreate_cm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-52-ea1878005f21>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, input_ids, attention_mask, train)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;31m#### Transfer Learning: name should be alpabet orders for the summary ####\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"A\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"B\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.7/contextlib.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recreate_cm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: __call__() takes 2 positional arguments but 3 were given"]}],"source":["main(seed, pretrained_roberta, dummy_input_ids, dummy_attention_mask)"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"Main.ipynb","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}