{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Main.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","metadata":{"id":"view-in-github"},"source":["<a href=\"https://colab.research.google.com/github/ayami-n/Flax_text_prediction/blob/main/Main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"2DeZbEYMnwWN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1658018607053,"user_tz":-600,"elapsed":20694,"user":{"displayName":"Yuji Ishikawa","userId":"17475269684774678602"}},"outputId":"dfddd107-2197-4cf1-df1d-138410359e38"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["%cd /content/drive/MyDrive/Flax_text_prediction"],"metadata":{"id":"qhezgqRvnzTS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1658018626639,"user_tz":-600,"elapsed":487,"user":{"displayName":"Yuji Ishikawa","userId":"17475269684774678602"}},"outputId":"642604d1-0e36-497b-dc2b-d9b9d0aec991"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Flax_text_prediction\n"]}]},{"cell_type":"markdown","source":["# Import libs"],"metadata":{"id":"NRKyEoECnnSd"}},{"cell_type":"code","source":["%%capture\n","!pip install datasets\n","!pip install git+https://github.com/huggingface/transformers.git\n","!pip install flax\n","!pip install git+https://github.com/deepmind/optax.git"],"metadata":{"id":"Iv2TRPsJpyAM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import jax\n","from jax import random  # to create random values for initalizing a model (Flax requires)\n","import jax.numpy as jnp\n","\n","# Flax for building model\n","try:\n","    import flax\n","except ModuleNotFoundError: # Install flax if missing\n","    !pip install --quiet flax\n","    import flax\n","\n","from flax import linen as nn\n","from flax.training import train_state, checkpoints\n","\n","# Optax for optimizor \n","import optax\n","\n","# Transformers\n","!pip install transformers\n","from transformers import FlaxAutoModelForSequenceClassification, AutoConfig\n","from transformers import RobertaTokenizer, RobertaConfig # as we use Roberta model\n","\n","# others\n","import pandas as pd\n","from tqdm import tqdm"],"metadata":{"id":"epCnK0nRnmhW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1658020107897,"user_tz":-600,"elapsed":3006,"user":{"displayName":"Yuji Ishikawa","userId":"17475269684774678602"}},"outputId":"e91c708c-6278-41ee-9449-7dc2e7174ae5"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.20.1)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.1)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.8.1)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n"]}]},{"cell_type":"markdown","source":["# Config"],"metadata":{"id":"IVImuz8mpJXl"}},{"cell_type":"code","source":["model_checkpoint = 'siebert/sentiment-roberta-large-english' # https://huggingface.co/docs/transformers/model_doc/roberta#roberta\n","num_labels = 3 # our targets\n","seed = 0  # for building our model\n","max_len = 256  # input text should be the same length\n","\n","config = AutoConfig.from_pretrained(model_checkpoint, num_labels=num_labels)  # create a config for our model"],"metadata":{"id":"roAJE2JZpLjv","executionInfo":{"status":"ok","timestamp":1658019833631,"user_tz":-600,"elapsed":3,"user":{"displayName":"Yuji Ishikawa","userId":"17475269684774678602"}}},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":["# Tokenaization"],"metadata":{"id":"zduhy-t_m7q1"}},{"cell_type":"code","source":["df = pd.read_csv(\"./kaggle/train.csv\")  # import train datasets\n","new_label = {\"discourse_effectiveness\": {\"Ineffective\": 0, \"Adequate\": 1, \"Effective\": 2}}  # to replace \n","df = df.replace(new_label) "],"metadata":{"id":"MBotyWi7nFlv","executionInfo":{"status":"ok","timestamp":1658020632877,"user_tz":-600,"elapsed":483,"user":{"displayName":"Yuji Ishikawa","userId":"17475269684774678602"}}},"execution_count":31,"outputs":[]},{"cell_type":"code","source":["def tokenaize(texts, tokenizer, max_len):  # df text comes and return as numerical \n","    input_ids = []\n","    attention_mask = []\n","    \n","    for text in tqdm(texts):  # it takes over 1 min (numpy and list)\n","        token = tokenizer(text, max_length=max_len, truncation=True, padding='max_length',\n","                         add_special_tokens=True,  return_tensors='jax')\n","        input_ids.append(token['input_ids']) # separate: the values (text) are converted by the tokenizer\n","        attention_mask.append(token['attention_mask']) # separate: the values (attention-mask) are converted by the tokenizer\n","        \n","    return jnp.array(input_ids), jnp.array(attention_mask)"],"metadata":{"id":"DobpcytJn15n","executionInfo":{"status":"ok","timestamp":1658020140422,"user_tz":-600,"elapsed":362,"user":{"displayName":"Yuji Ishikawa","userId":"17475269684774678602"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["tokenizer = RobertaTokenizer.from_pretrained(model_checkpoint)  # this tokenizer converts numeric from string: the values are different if you select different model_checkpoint\n","input_ids, attention_mask = tokenaize(df['discourse_text'].to_numpy(), tokenizer, max_len)  # pandas is slow -> numpy is the fastest (list is considerable)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FqZ_TapDqXwR","executionInfo":{"status":"ok","timestamp":1658020447308,"user_tz":-600,"elapsed":104957,"user":{"displayName":"Yuji Ishikawa","userId":"17475269684774678602"}},"outputId":"3624d661-56f6-40df-d7b0-45efd1c0299b"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 36765/36765 [01:25<00:00, 430.79it/s]\n"]}]},{"cell_type":"markdown","source":["# Create a model"],"metadata":{"id":"2FC74pNhnDIW"}},{"cell_type":"code","source":["model = FlaxAutoModelForSequenceClassification.from_pretrained(model_checkpoint, config=config, seed=seed, ignore_mismatched_sizes=True)  # ignore_mismatched_sizes=True: arrow to have arbitary number of outputs"],"metadata":{"id":"Z0V58UuSs4EW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1657868739612,"user_tz":-600,"elapsed":3356,"user":{"displayName":"Yuji Ishikawa","userId":"17475269684774678602"}},"outputId":"765f61a9-885b-419f-b58c-287d67b9e921"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of FlaxRobertaForSequenceClassification were not initialized from the model checkpoint at siebert/sentiment-roberta-large-english and are newly initialized because the shapes did not match:\n","- ('classifier', 'out_proj', 'bias'): found shape (2,) in the checkpoint and (3,) in the model instantiated\n","- ('classifier', 'out_proj', 'kernel'): found shape (1024, 2) in the checkpoint and (1024, 3) in the model instantiated\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}]},{"cell_type":"code","source":["out = model(**inputs)\n","print(out)\n","print(out.logits)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hjtVxyp1uCtN","executionInfo":{"status":"ok","timestamp":1657868770007,"user_tz":-600,"elapsed":5676,"user":{"displayName":"Yuji Ishikawa","userId":"17475269684774678602"}},"outputId":"62f5cb1b-02a5-4efe-a29d-79544beb1657"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["FlaxSequenceClassifierOutput(logits=DeviceArray([[-0.4148041 , -0.48419115,  0.02517768]], dtype=float32), hidden_states=None, attentions=None)\n","[[-0.4148041  -0.48419115  0.02517768]]\n"]}]}]}